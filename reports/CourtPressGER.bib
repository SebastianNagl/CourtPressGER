@inproceedings{glaserSummarizationGermanCourt2021,
  title = {Summarization of {{German Court Rulings}}},
  booktitle = {Proceedings of the {{Natural Legal Language Processing Workshop}} 2021},
  author = {Glaser, Ingo and Moser, Sebastian and Matthes, Florian},
  year = {2021},
  pages = {180--189},
  publisher = {Association for Computational Linguistics},
  address = {Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.nllp-1.19},
  urldate = {2025-05-05},
  abstract = {Historically speaking, the German legal language is widely neglected in NLP research, especially in summarization systems, as most of them are based on English newspaper articles. In this paper, we propose the task of automatic summarization of German court rulings. Due to their complexity and length, it is of critical importance that legal practitioners can quickly identify the content of a verdict and thus be able to decide on the relevance for a given legal case. To tackle this problem, we introduce a new dataset consisting of 100k German judgments with short summaries. Our dataset has the highest compression ratio among the most common summarization datasets. German court rulings contain much structural information, so we create a pre-processing pipeline tailored explicitly to the German legal domain. Additionally, we implement multiple extractive as well as abstractive summarization systems and build a wide variety of baseline models. Our best model achieves a ROUGE-1 score of 30.50. Therefore with this work, we are laying the crucial groundwork for further research on German summarization systems.},
  langid = {english},
  keywords = {notion},
  file = {/Users/sebastiannagl/Zotero/storage/BII3XCF9/Glaser et al. - 2021 - Summarization of German Court Rulings.pdf}
}

@misc{rolshovenUnlockingLegalKnowledge2024,
  title = {Unlocking {{Legal Knowledge}}: {{A Multilingual Dataset}} for {{Judicial Summarization}} in {{Switzerland}}},
  shorttitle = {Unlocking {{Legal Knowledge}}},
  author = {Rolshoven, Luca and Rasiah, Vishvaksenan and Bose, Srinanda Br{\"u}gger and St{\"u}rmer, Matthias and Niklaus, Joel},
  year = {2024},
  month = oct,
  number = {arXiv:2410.13456},
  eprint = {2410.13456},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.13456},
  urldate = {2025-05-05},
  abstract = {Legal research is a time-consuming task that most lawyers face on a daily basis. A large part of legal research entails looking up relevant caselaw and bringing it in relation to the case at hand. Lawyers heavily rely on summaries (also called headnotes) to find the right cases quickly. However, not all decisions are annotated with headnotes and writing them is time-consuming. Automated headnote creation has the potential to make hundreds of thousands of decisions more accessible for legal research in Switzerland alone. To kickstart this, we introduce the Swiss Leading Decision Summarization (SLDS) dataset, a novel cross-lingual resource featuring 18K court rulings from the Swiss Federal Supreme Court (SFSC), in German, French, and Italian, along with German headnotes. We fine-tune and evaluate three mT5 variants, along with proprietary models. Our analysis highlights that while proprietary models perform well in zero-shot and one-shot settings, fine-tuned smaller models still provide a strong competitive edge. We publicly release the dataset to facilitate further research in multilingual legal summarization and the development of assistive technologies for legal professionals.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,notion},
  file = {/Users/sebastiannagl/Zotero/storage/S5MA74CZ/Rolshoven et al. - 2024 - Unlocking Legal Knowledge A Multilingual Dataset for Judicial Summarization in Switzerland.pdf}
}

@inproceedings{steffesEvaluatingLegalSummaries2023,
  title = {On Evaluating Legal Summaries with {{ROUGE}}},
  booktitle = {Proceedings of the {{Nineteenth International Conference}} on {{Artificial Intelligence}} and {{Law}}},
  author = {Steffes, Bianca and Rataj, Piotr and Burger, Luise and Roth, Lukas},
  year = {2023},
  month = jun,
  pages = {457--461},
  publisher = {ACM},
  address = {Braga Portugal},
  doi = {10.1145/3594536.3595150},
  urldate = {2025-05-05},
  abstract = {ROUGE is the most commonly used measure for evaluating summarization algorithms in practice. However, it is questionable whether ROUGE scores adequately reflect the quality of summaries in terms of content. We introduce a metric to measure (legal) content of summaries based on exhaustiveness and concreteness and compare ROUGE scores with values generated by legal experts according to our metric on two tasks. Our results show that ROUGE does not reliably gauge legal content and thus should not be used as a single indicator for the quality of summarization algorithms. For our particular use case we furthermore show one way to increase the reliability of ROUGE by pre-selecting sentences.},
  isbn = {979-8-4007-0197-9},
  langid = {english},
  keywords = {notion},
  file = {/Users/sebastiannagl/Zotero/storage/R3NPYHYV/Steffes et al. - 2023 - On evaluating legal summaries with ROUGE.pdf}
}

@incollection{steffesLegalTextSummarization2022,
  title = {Legal {{Text Summarization Using Argumentative Structures}}},
  booktitle = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  author = {Steffes, Bianca and Rataj, Piotr},
  editor = {Francesconi, Enrico and Borges, Georg and Sorge, Christoph},
  year = {2022},
  month = dec,
  publisher = {IOS Press},
  doi = {10.3233/FAIA220474},
  urldate = {2025-05-05},
  abstract = {Legal text summarization focuses on the automated creation of summaries for legal texts. We show that the argumentative structure of judgments can improve the selection of guiding principles as a specific kind of summary using judgments of the German Federal Court of Justice as measured by the ROUGE metric. We evaluate our first results and put them in the context of our ongoing work.},
  copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
  isbn = {978-1-64368-364-5 978-1-64368-365-2},
  langid = {english},
  keywords = {notion},
  file = {/Users/sebastiannagl/Zotero/storage/UF9X2SPY/Steffes and Rataj - 2022 - Legal Text Summarization Using Argumentative Structures.pdf}
}

@incollection{xuQuestionAnsweringApproachEvaluating2023,
  title = {Question-{{Answering Approach}} to {{Evaluating Legal Summaries}}},
  author = {Xu, Huihui and Ashley, Kevin},
  year = {2023},
  month = dec,
  eprint = {2309.15016},
  primaryclass = {cs},
  doi = {10.3233/FAIA230977},
  urldate = {2025-05-05},
  abstract = {Traditional evaluation metrics like ROUGE compare lexical overlap between the reference and generated summaries without taking argumentative structure into account, which is important for legal summaries. In this paper, we propose a novel legal summarization evaluation framework that utilizes GPT-4 to generate a set of question-answer pairs that cover main points and information in the reference summary. GPT-4 is then used to produce answers based on the generated summary for the questions from the reference summary. Finally, GPT-4 grades the answers from the reference summary and the generated summary. We examined the correlation between GPT-4 grading and human grading. The results suggest that this question-answering approach with GPT-4 can be a useful tool for gauging the quality of the summary.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,notion},
  file = {/Users/sebastiannagl/Zotero/storage/T2F8BWHL/Xu and Ashley - 2023 - Question-Answering Approach to Evaluating Legal Summaries.pdf}
}
