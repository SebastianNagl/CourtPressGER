{
  "llama_3_3_70B_generated_judgement_summary": {
    "count": 14,
    "avg_rank": 4.071,
    "hallucination_rate": 0.714,
    "incoherent_rate": 0.071,
    "publishable_rate": 0.571,
    "ranks": [
      1,
      2,
      2,
      4,
      4,
      1,
      2,
      4,
      6,
      7,
      7,
      7,
      5,
      5
    ]
  },
  "reference_summary": {
    "count": 14,
    "avg_rank": 1.5,
    "hallucination_rate": 0.786,
    "incoherent_rate": 0.071,
    "publishable_rate": 1.0,
    "ranks": [
      2,
      1,
      1,
      1,
      1,
      2,
      1,
      1,
      1,
      1,
      1,
      4,
      1,
      3
    ]
  },
  "openai_gpt_4o_generated_judgement_summary": {
    "count": 14,
    "avg_rank": 4.0,
    "hallucination_rate": 0.643,
    "incoherent_rate": 0.0,
    "publishable_rate": 0.714,
    "ranks": [
      3,
      4,
      3,
      7,
      5,
      4,
      6,
      5,
      3,
      3,
      6,
      2,
      3,
      2
    ]
  },
  "openai_gpt_4o_gen_hier_summary": {
    "count": 14,
    "avg_rank": 4.5,
    "hallucination_rate": 0.571,
    "incoherent_rate": 0.071,
    "publishable_rate": 0.786,
    "ranks": [
      4,
      3,
      6,
      5,
      3,
      5,
      4,
      3,
      2,
      8,
      4,
      5,
      2,
      9
    ]
  },
  "llama_3_3_70B_gen_hier_summary": {
    "count": 14,
    "avg_rank": 4.714,
    "hallucination_rate": 0.714,
    "incoherent_rate": 0.0,
    "publishable_rate": 0.571,
    "ranks": [
      5,
      5,
      5,
      2,
      2,
      3,
      8,
      2,
      7,
      5,
      5,
      6,
      7,
      4
    ]
  },
  "mistral_v03_generated_judgement_summary": {
    "count": 14,
    "avg_rank": 5.857,
    "hallucination_rate": 0.714,
    "incoherent_rate": 0.214,
    "publishable_rate": 0.214,
    "ranks": [
      6,
      9,
      7,
      9,
      11,
      9,
      5,
      9,
      5,
      4,
      2,
      1,
      4,
      1
    ]
  },
  "llama_3_8b_gen_hier_summary": {
    "count": 14,
    "avg_rank": 6.429,
    "hallucination_rate": 0.714,
    "incoherent_rate": 0.071,
    "publishable_rate": 0.214,
    "ranks": [
      7,
      6,
      4,
      6,
      8,
      6,
      9,
      7,
      4,
      9,
      3,
      8,
      6,
      7
    ]
  },
  "mistral_v03_gen_hier_summary": {
    "count": 14,
    "avg_rank": 7.714,
    "hallucination_rate": 1.0,
    "incoherent_rate": 0.143,
    "publishable_rate": 0.143,
    "ranks": [
      8,
      7,
      8,
      11,
      7,
      7,
      7,
      8,
      9,
      2,
      9,
      9,
      10,
      6
    ]
  },
  "eurollm_gen_hier_summary": {
    "count": 14,
    "avg_rank": 7.143,
    "hallucination_rate": 0.786,
    "incoherent_rate": 0.286,
    "publishable_rate": 0.214,
    "ranks": [
      9,
      8,
      9,
      3,
      6,
      8,
      10,
      6,
      8,
      6,
      8,
      3,
      8,
      8
    ]
  },
  "teuken_gen_hier_summ_summary-press-summary-v2": {
    "count": 14,
    "avg_rank": 9.857,
    "hallucination_rate": 0.929,
    "incoherent_rate": 0.214,
    "publishable_rate": 0.071,
    "ranks": [
      10,
      11,
      10,
      10,
      9,
      11,
      3,
      11,
      11,
      11,
      10,
      11,
      9,
      11
    ]
  },
  "teuken_gen_hier_summary": {
    "count": 14,
    "avg_rank": 10.214,
    "hallucination_rate": 0.714,
    "incoherent_rate": 0.214,
    "publishable_rate": 0.0,
    "ranks": [
      11,
      10,
      11,
      8,
      10,
      10,
      11,
      10,
      10,
      10,
      11,
      10,
      11,
      10
    ]
  }
}