{
    "models": [
        {
            "type": "openai",
            "name": "gpt-4o",
            "model": "gpt-4o",
            "max_tokens": 2048,
            "temperature": 0.7,
            "category": "groß",
            "description": "OpenAI GPT-4o Modell für hochqualitative Textgenerierung"
        },
        {
            "type": "deepinfra",
            "name": "llama-70b",
            "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
            "max_tokens": 2048,
            "temperature": 0.7,
            "category": "groß",
            "description": "Meta Llama 3.3 70B über DeepInfra API"
        },
        {
            "type": "local",
            "name": "teuken-7b",
            "model_path": "models/teuken",
            "max_length": 1024,
            "temperature": 0.7,
            "category": "klein",
            "description": "Teuken-7B Modell für lokale Generierung"
        },
        {
            "type": "local",
            "name": "llama3-8b",
            "model_path": "models/llama3-8b",
            "max_length": 1024,
            "temperature": 0.7,
            "category": "klein",
            "description": "Llama-3-8B Modell für lokale Generierung"
        },
        {
            "type": "local",
            "name": "eurollm-9b",
            "model_path": "models/eurollm",
            "max_length": 1024,
            "temperature": 0.7,
            "category": "klein",
            "description": "EuroLLM-9B Modell für lokale Generierung"
        }
    ]
} 