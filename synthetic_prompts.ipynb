{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67517895",
   "metadata": {},
   "source": [
    "# Generierung synthetischer Prompts für Gerichtsurteile und Pressemitteilungen\n",
    "\n",
    "Dieses Notebook verwendet die Claude API, um synthetische Prompts für die Pressemitteilungen - Gerichtsurteilen Paare zu erstellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e366f61",
   "metadata": {},
   "source": [
    "## 1. Setup und Datensatz-Laden\n",
    "\n",
    "Zuerst importieren wir die notwendigen Bibliotheken und laden den bereinigten Datensatz aus `bereinigung.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import anthropic\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Lade den bereinigten Datensatz\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_data/cleaned_combined_methods.csv')\n",
    "    print(f\"Bereinigter Datensatz mit {len(df)} Einträgen geladen\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Bereinigter Datensatz nicht gefunden. Bitte führe zuerst bereinigung.ipynb aus.\")\n",
    "    # Für Demonstrationszwecke fahren wir fort, als ob der Datensatz existieren würde\n",
    "\n",
    "# Stichprobe des Datensatzes für Tests (für Produktionseinsatz auskommentiert)\n",
    "# df = df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c534023",
   "metadata": {},
   "source": [
    "## 2. Setup Claude API-Zugang\n",
    "\n",
    "Als nächstes richten wir die Verbindung zur Claude API ein. Wir verwenden den Anthropic Python-Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c54166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup des Claude API-Clients\n",
    "# Besorge deinen API-Schlüssel von https://console.anthropic.com/\n",
    "# Setze deinen API-Schlüssel als Umgebungsvariable oder direkt hier (nicht empfohlen für geteilte Notebooks)\n",
    "\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    ANTHROPIC_API_KEY = input(\"Bitte gib deinen Anthropic API-Schlüssel ein: \")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "# Initialisiere den Claude-Client\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "# Teste die API-Verbindung\n",
    "try:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=100,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Hallo, Claude! Bitte antworte mit einer sehr kurzen Begrüßung.\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"API-Verbindung erfolgreich!\")\n",
    "    print(f\"Claude sagt: {response.content[0].text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der Verbindung zur Claude API: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ce810",
   "metadata": {},
   "source": [
    "## 3. Hilfsfunktionen für die Generierung synthetischer Prompts\n",
    "\n",
    "Wir erstellen Hilfsfunktionen, um synthetische Prompts aus den Gerichtsurteilen und Pressemitteilungen zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_prompt(court_ruling, press_release, model=\"claude-3-haiku-20240307\", retries=3, wait_time=2):\n",
    "    \"\"\"\n",
    "    Generiert einen synthetischen Prompt, der die gegebene Pressemitteilung aus dem Gerichtsurteil erzeugen könnte.\n",
    "    \n",
    "    Args:\n",
    "        court_ruling (str): Der Text des Gerichtsurteils\n",
    "        press_release (str): Der Text der Pressemitteilung\n",
    "        model (str): Das zu verwendende Claude-Modell\n",
    "        retries (int): Anzahl der Wiederholungsversuche bei API-Fehlern\n",
    "        wait_time (int): Wartezeit zwischen Wiederholungsversuchen in Sekunden\n",
    "        \n",
    "    Returns:\n",
    "        str: Der generierte synthetische Prompt\n",
    "    \"\"\"\n",
    "    # Vorbereitung des System-Prompts\n",
    "    system_prompt = \"\"\"\n",
    "    Du bist ein Experte für juristische Texte und Kommunikation. Deine Aufgabe ist es, ein Gerichtsurteil und die \n",
    "    dazugehörige Pressemitteilung zu analysieren und dann herauszufinden, welcher Prompt verwendet worden sein könnte, \n",
    "    um diese Pressemitteilung aus dem Gerichtsurteil zu generieren, wenn man ihn einem LLM gegeben hätte.\n",
    "    \n",
    "    1. Analysiere, wie die Pressemitteilung Informationen aus dem Urteil vereinfacht, umstrukturiert und Schlüsselinformationen hervorhebt\n",
    "    2. Berücksichtige den Ton, die Struktur und den Detaillierungsgrad der Pressemitteilung\n",
    "    3. Identifiziere, welche Anweisungen nötig wären, um den juristischen Text in diese Pressemitteilung zu transformieren\n",
    "    \n",
    "    Erkläre NICHT deine Überlegungen und füge KEINE Meta-Kommentare hinzu. Gib NUR den tatsächlichen Prompt aus, der die \n",
    "    Pressemitteilung aus dem Gerichtsurteil generieren würde. Sei spezifisch und detailliert in deinem synthetisierten Prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Vorbereitung des Benutzer-Prompts\n",
    "    user_prompt = f\"\"\"\n",
    "    Hier ist das originale Gerichtsurteil:\n",
    "    \n",
    "    ```\n",
    "    {court_ruling}\n",
    "    ```\n",
    "    \n",
    "    Und hier ist die Pressemitteilung, die daraus erstellt wurde:\n",
    "    \n",
    "    ```\n",
    "    {press_release}\n",
    "    ```\n",
    "    \n",
    "    Erstelle einen detaillierten Prompt, der einem LLM gegeben werden könnte, um die obige Pressemitteilung aus dem Gerichtsurteil zu generieren. \n",
    "    Schreibe NUR den Prompt selbst, ohne Erklärungen oder Meta-Kommentare.\n",
    "    \"\"\"\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=1000,\n",
    "                system=system_prompt,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "            )\n",
    "            return response.content[0].text.strip()\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                print(f\"Fehler: {e}. Neuer Versuch in {wait_time} Sekunden...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Nach {retries} Versuchen fehlgeschlagen: {e}\")\n",
    "                return f\"Fehler bei der Generierung des Prompts: {e}\"\n",
    "\n",
    "def process_batch(df, batch_size=10, start_idx=0, save_interval=10):\n",
    "    \"\"\"\n",
    "    Verarbeitet einen Dataframe in Batches und generiert synthetische Prompts für jede Zeile.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Der Dataframe mit Gerichtsurteilen und Pressemitteilungen\n",
    "        batch_size (int): Anzahl der Elemente, die vor dem Speichern von Zwischenergebnissen verarbeitet werden\n",
    "        start_idx (int): Index, bei dem die Verarbeitung beginnen soll (für die Wiederaufnahme)\n",
    "        save_interval (int): Wie oft Zwischenergebnisse gespeichert werden sollen\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Der Dataframe mit hinzugefügten synthetischen Prompts\n",
    "    \"\"\"\n",
    "    # Erstelle eine synthetic_prompt-Spalte, falls sie nicht existiert\n",
    "    if 'synthetic_prompt' not in df.columns:\n",
    "        df['synthetic_prompt'] = None\n",
    "    \n",
    "    # Erstelle ein Verzeichnis für Checkpoints, falls es nicht existiert\n",
    "    checkpoint_dir = Path('checkpoints')\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Verarbeite in Batches\n",
    "    for i in tqdm(range(start_idx, len(df), batch_size)):\n",
    "        batch_end = min(i + batch_size, len(df))\n",
    "        batch = df.iloc[i:batch_end].copy()\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            if pd.isna(df.at[idx, 'synthetic_prompt']):\n",
    "                court_ruling = row['judgement']\n",
    "                press_release = row['summary']\n",
    "                \n",
    "                # Kürze sehr lange Eingaben, um Token-Limits zu vermeiden\n",
    "                if len(court_ruling) > 15000:\n",
    "                    court_ruling = court_ruling[:15000] + \"...\"\n",
    "                if len(press_release) > 5000:\n",
    "                    press_release = press_release[:5000] + \"...\"\n",
    "                \n",
    "                # Generiere den synthetischen Prompt\n",
    "                synthetic_prompt = generate_synthetic_prompt(court_ruling, press_release)\n",
    "                df.at[idx, 'synthetic_prompt'] = synthetic_prompt\n",
    "                \n",
    "                # Zeige Fortschritt an\n",
    "                if (idx - i) % 5 == 0 or idx == batch_end - 1:\n",
    "                    print(f\"{idx+1}/{len(df)} Einträge verarbeitet\")\n",
    "        \n",
    "        # Speichere Checkpoint in regelmäßigen Abständen\n",
    "        if (i // batch_size) % save_interval == 0 or batch_end == len(df):\n",
    "            checkpoint_path = checkpoint_dir / f\"synthetic_prompts_checkpoint_{batch_end}.csv\"\n",
    "            df.to_csv(checkpoint_path, index=False)\n",
    "            print(f\"Checkpoint gespeichert unter {checkpoint_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d689d",
   "metadata": {},
   "source": [
    "## 4. Checkpoint laden oder von vorne beginnen\n",
    "\n",
    "Wir prüfen, ob es eine Checkpoint-Datei gibt, um von dort fortzufahren, oder beginnen die Verarbeitung von Anfang an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfe auf vorhandene Checkpoints\n",
    "checkpoint_dir = Path('checkpoints')\n",
    "checkpoint_files = list(checkpoint_dir.glob(\"synthetic_prompts_checkpoint_*.csv\")) if checkpoint_dir.exists() else []\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "if checkpoint_files:\n",
    "    # Finde den neuesten Checkpoint basierend auf der Nummer im Dateinamen\n",
    "    latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.stem.split('_')[-1]))\n",
    "    print(f\"Neuester Checkpoint gefunden: {latest_checkpoint}\")\n",
    "    \n",
    "    # Frage, ob vom Checkpoint fortgefahren werden soll\n",
    "    continue_from_checkpoint = input(\"Vom letzten Checkpoint fortfahren? (j/n): \").lower().strip() == 'j'\n",
    "    \n",
    "    if continue_from_checkpoint:\n",
    "        # Lade den Checkpoint\n",
    "        df = pd.read_csv(latest_checkpoint)\n",
    "        print(f\"Checkpoint mit {len(df)} Einträgen geladen\")\n",
    "        \n",
    "        # Finde die erste Zeile ohne synthetischen Prompt\n",
    "        if 'synthetic_prompt' in df.columns:\n",
    "            missing_prompts = df['synthetic_prompt'].isna()\n",
    "            if missing_prompts.any():\n",
    "                start_idx = missing_prompts.idxmax()\n",
    "                print(f\"Verarbeitung wird ab Index {start_idx} fortgesetzt\")\n",
    "            else:\n",
    "                print(\"Alle Einträge haben bereits synthetische Prompts!\")\n",
    "        else:\n",
    "            print(\"Keine synthetic_prompt-Spalte im Checkpoint gefunden, beginne von vorne\")\n",
    "    else:\n",
    "        print(\"Starte neue Verarbeitung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2a7b6",
   "metadata": {},
   "source": [
    "## 5. Synthetische Prompts generieren\n",
    "\n",
    "Jetzt verarbeiten wir den Datensatz, um die synthetischen Prompts zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguriere Parameter für die Batch-Verarbeitung\n",
    "batch_size = 10  # Verarbeite 10 Einträge auf einmal\n",
    "save_interval = 5  # Speichere Checkpoint alle 5 Batches\n",
    "\n",
    "# Verarbeite den Datensatz\n",
    "print(f\"Starte Generierung synthetischer Prompts für {len(df)} Einträge ab Index {start_idx}\")\n",
    "df = process_batch(df, batch_size=batch_size, start_idx=start_idx, save_interval=save_interval)\n",
    "\n",
    "# Speichere das endgültige Ergebnis\n",
    "output_path = Path('data/court_press_with_synthetic_prompts.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Vollständiger Datensatz mit synthetischen Prompts gespeichert unter {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b0ace",
   "metadata": {},
   "source": [
    "## 6. Beispiele der generierten synthetischen Prompts analysieren\n",
    "\n",
    "Schauen wir uns einige Beispiele der generierten synthetischen Prompts an, um die Art der Anweisungen zu verstehen, die Claude vorgeschlagen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wähle einige Beispiele zur Anzeige aus\n",
    "if 'synthetic_prompt' in df.columns and not df['synthetic_prompt'].isna().all():\n",
    "    # Hole 5 zufällige Beispiele, bei denen synthetic_prompt nicht None/NaN ist\n",
    "    sample_df = df[df['synthetic_prompt'].notna()].sample(min(5, len(df[df['synthetic_prompt'].notna()])))\n",
    "    \n",
    "    for i, (_, row) in enumerate(sample_df.iterrows(), 1):\n",
    "        print(f\"\\n==== Beispiel {i} ====\")\n",
    "        print(f\"Gerichtsfall-ID: {row['id']}\")\n",
    "        print(\"\\nSynthetischer Prompt:\")\n",
    "        print(row['synthetic_prompt'])\n",
    "        \n",
    "        # Optional, zeige auch den ersten Teil der Pressemitteilung\n",
    "        print(\"\\nErste 150 Zeichen der Pressemitteilung:\")\n",
    "        print(row['summary'][:150] + \"...\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Noch keine synthetischen Prompts verfügbar. Führe zunächst die Verarbeitungszelle aus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3bc3d7",
   "metadata": {},
   "source": [
    "## 7. Muster in den synthetischen Prompts analysieren\n",
    "\n",
    "Analysieren wir die generierten Prompts, um häufige Muster und Eigenschaften zu identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfe, ob wir Prompts zur Analyse haben\n",
    "if 'synthetic_prompt' in df.columns and not df['synthetic_prompt'].isna().all():\n",
    "    # Erstelle einen Dataframe nur mit den synthetischen Prompts für die Analyse\n",
    "    prompts_df = df[df['synthetic_prompt'].notna()].copy()\n",
    "    \n",
    "    # Berechne grundlegende Statistiken\n",
    "    prompt_lengths = prompts_df['synthetic_prompt'].str.len()\n",
    "    avg_length = prompt_lengths.mean()\n",
    "    min_length = prompt_lengths.min()\n",
    "    max_length = prompt_lengths.max()\n",
    "    \n",
    "    print(f\"Anzahl synthetischer Prompts: {len(prompts_df)}\")\n",
    "    print(f\"Durchschnittliche Prompt-Länge: {avg_length:.1f} Zeichen\")\n",
    "    print(f\"Kürzester Prompt: {min_length} Zeichen\")\n",
    "    print(f\"Längster Prompt: {max_length} Zeichen\")\n",
    "    \n",
    "    # Suche nach häufigen Phrasen oder Anweisungstypen in den Prompts\n",
    "    common_phrases = [\n",
    "        \"zusammenfassen\", \"vereinfachen\", \"erklären\", \"übersetzen\", \"umwandeln\", \n",
    "        \"transformieren\", \"erstelle eine pressemitteilung\", \"schreibe eine pressemitteilung\", \n",
    "        \"nicht-technisch\", \"laien\", \"öffentliches publikum\", \"prägnant\"\n",
    "    ]\n",
    "    \n",
    "    phrase_counts = {}\n",
    "    for phrase in common_phrases:\n",
    "        count = prompts_df['synthetic_prompt'].str.lower().str.contains(phrase).sum()\n",
    "        if count > 0:\n",
    "            phrase_counts[phrase] = count\n",
    "    \n",
    "    # Konvertiere Anzahl in Prozentsätze\n",
    "    phrase_percentages = {k: v/len(prompts_df)*100 for k, v in phrase_counts.items()}\n",
    "    \n",
    "    # Sortiere nach Häufigkeit\n",
    "    sorted_phrases = sorted(phrase_percentages.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nHäufige Anweisungstypen in synthetischen Prompts:\")\n",
    "    for phrase, percentage in sorted_phrases:\n",
    "        print(f\"{phrase}: {percentage:.1f}% der Prompts\")\n",
    "else:\n",
    "    print(\"Noch keine synthetischen Prompts verfügbar. Führe zunächst die Verarbeitungszelle aus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a465c42",
   "metadata": {},
   "source": [
    "## 8. Datensatz für weitere Analysen exportieren\n",
    "\n",
    "Schließlich speichern wir unseren Datensatz mit den synthetischen Prompts für weitere Analysen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57608b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eine endgültige Version des Datensatzes mit Spalten in einer logischen Reihenfolge\n",
    "if 'synthetic_prompt' in df.columns:\n",
    "    # Reorganisiere Spalten in einer logischen Reihenfolge\n",
    "    columns_order = [\n",
    "        'id', 'date', 'subset_name', 'split_name',  # Kennungen\n",
    "        'synthetic_prompt',  # Neue generierte Spalte\n",
    "        'summary', 'judgement'  # Ursprüngliche Textspalten\n",
    "    ]\n",
    "    \n",
    "    # Füge alle verbleibenden Spalten hinzu\n",
    "    remaining_columns = [col for col in df.columns if col not in columns_order]\n",
    "    final_columns = columns_order + remaining_columns\n",
    "    \n",
    "    # Erstelle endgültigen Datensatz mit Spalten in gewünschter Reihenfolge\n",
    "    final_df = df[final_columns].copy()\n",
    "    \n",
    "    # Speichere als endgültigen Datensatz\n",
    "    final_output_path = Path('data/court_press_with_synthetic_prompts_final.csv')\n",
    "    final_df.to_csv(final_output_path, index=False)\n",
    "    print(f\"Endgültiger Datensatz mit {len(final_df)} Einträgen gespeichert unter {final_output_path}\")\n",
    "    \n",
    "    # Speichere auch eine leichtere Version mit nur den wesentlichen Spalten\n",
    "    essential_columns = ['id', 'date', 'subset_name', 'split_name', 'synthetic_prompt', 'summary', 'judgement']\n",
    "    essential_df = final_df[essential_columns].copy()\n",
    "    \n",
    "    essential_output_path = Path('data/court_press_with_synthetic_prompts_essential.csv')\n",
    "    essential_df.to_csv(essential_output_path, index=False)\n",
    "    print(f\"Wesentlicher Datensatz mit {len(essential_df)} Einträgen gespeichert unter {essential_output_path}\")\n",
    "else:\n",
    "    print(\"Noch keine synthetischen Prompts verfügbar. Führe zunächst die Verarbeitungszelle aus.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
